{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "import unicodedata\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "from hindsight_feed_db import fetch_content_generators, fetch_contents\n",
    "import utils\n",
    "from feed_generator import FeedGenerator\n",
    "from feeders.exa_topic.exa_topic import ExaTopicFeeder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_generators = fetch_content_generators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exa_content_generators = [cg for cg in content_generators if cg.gen_type == \"ExaTopicFeeder\"]\n",
    "exa_content_generators_ids = {cg.id for cg in exa_content_generators}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = fetch_contents(non_viewed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_added_timestamp = max([c.timestamp for c in content])\n",
    "newly_interacted_content = [c for c in content if c.last_modified_timestamp > last_added_timestamp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "exa_content = [c for c in content if c.content_generator_id in exa_content_generators_ids]\n",
    "clicked_content = [c for c in exa_content if c.clicked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_dive_deeper_prompt(content):\n",
    "#     prompt = \"\"\"You are an assistant whose task is to create a search query for a embedding search database to help a user find content that\n",
    "#                 they are interested in. Below is text from content that the user has recently been interested in:\n",
    "#                 \"\"\"\n",
    "\n",
    "#     for c in content:\n",
    "#         prompt += f\"New content:\\nTitle:{c.title}\"\n",
    "#         content_text = c.content_generator_specific_data['text']\n",
    "#         prompt += content_text + \"\\n\"\n",
    "\n",
    "#     prompt += \"\"\"Create a short, descriptive sentence to feed the embedding search database. Include as much information from different sources as possible. Answer\"\"\"\n",
    "#     return prompt\n",
    "\n",
    "def get_dive_deeper_prompt(content):\n",
    "    prompt = \"\"\"You are an assistant who generates search queries for an embedding search database to help a user find content of interest.\n",
    "\n",
    "    Below are excerpts from content that the user has recently engaged with:\n",
    "\n",
    "    \"\"\"\n",
    "    for c in content:\n",
    "        prompt += f\"Title: {c.title}\\n\"\n",
    "        content_text = c.content_generator_specific_data['text']\n",
    "        prompt += f\"{content_text}\\n\\n\"\n",
    "\n",
    "    prompt += \"\"\"Task:\n",
    "        - Analyze the content above.\n",
    "        - Identify the main themes and topics.\n",
    "        - Generate a single, concise sentence that summarizes the user's interests.\n",
    "        - Include as many relevant keywords and concepts from the content as possible.\n",
    "        - The sentence should be suitable as a search query for finding similar content.\n",
    "\n",
    "        Answer:\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked_cg_ids = {c.content_generator_id for c in clicked_content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_id_to_prompt = {}\n",
    "for cg_id in clicked_cg_ids:\n",
    "    cg_content = [c for c in clicked_content if c.content_generator_id == cg_id]\n",
    "    cg_id_to_prompt[cg_id] = get_dive_deeper_prompt(cg_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running with local LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlx_lm import load, generate\n",
    "\n",
    "def llm_generate(pipeline, prompt, max_tokens):\n",
    "    model, tokenizer = pipeline\n",
    "    return generate(model, tokenizer, prompt=prompt, max_tokens=max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 7 files: 100%|██████████| 7/7 [00:00<00:00, 13183.71it/s]\n"
     ]
    }
   ],
   "source": [
    "pipeline = load(\"mlx-community/Llama-3.1-SuperNova-Lite-bf16\")\n",
    "# pipeline = load(\"mlx-community/Meta-Llama-3.1-8B-Instruct-8bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_id_to_next_topic = {}\n",
    "for cg_id, prompt in cg_id_to_prompt.items():\n",
    "    cg_id_to_next_topic[cg_id] = llm_generate(pipeline=pipeline, prompt=prompt, max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \"Explainable AI, human-like intelligence, private AI, conversational AI, decision intelligence, AI governance, AI ethics, AI development, AI integration, AI workflow, AI models, AI training, AI customization, AI fine-tuning, AI as a service, AI for business, AI for enterprise, AI for finance, AI for healthcare, AI for security, AI for public sector, AI for ESG risk, AI for citizen services, AI for government, AI for professional services,\n",
      "2 The user is interested in exploring the intersection of artificial intelligence, human consciousness, and self-awareness, with a focus on the potential implications of AI on human identity and the nature of reality.\n",
      "3         \"I'm interested in AI, machine learning, algorithmic trading, deep learning, artificial intelligence, econophysics, quantitative hedge funds, algorithmic bias, algorithmic governance, and the intersection of technology and society.\"\n",
      "4         \"Personal AI, ChatGPT, Quarkus Embeddings, Redis Search, OpenShift, Strapi CMS, WebHooks, AI-generated portraits, custom prompts, vector similarity searches, low-code development, self-hosted backends, vector databases, machine learning, natural language processing, AI-assisted creativity, AI-powered productivity, AI-generated art, AI-driven innovation, AI research, AI development, AI applications, AI tools, AI services, AI platforms, AI ecosystems, AI communities\n"
     ]
    }
   ],
   "source": [
    "for cg_id, next_topic in cg_id_to_next_topic.items():\n",
    "    print(cg_id, next_topic.split(\"\\n\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_search_query_prompt(initial_response):\n",
    "    prompt = \"\"\"You are an assistant tasked with refining a search query generated by a previous analysis of user interests. Below is the initial query generated:\n",
    "\n",
    "    '{initial_response}'\n",
    "\n",
    "    Task:\n",
    "    - Review the initial query.\n",
    "    - Clarify and condense the query to better capture the essential themes and keywords.\n",
    "    - Ensure the refined query is sharp, specific, and optimized for searching related content.\n",
    "    - The refined query should be a single, succinct sentence that effectively encapsulates the user's core interests.\n",
    "\n",
    "    Refined Query:\"\"\"\n",
    "    return prompt.format(initial_response=initial_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_id_to_refined_next_topic = {}\n",
    "for cg_id, next_topic in cg_id_to_next_topic.items():\n",
    "    refine_prompt = refine_search_query_prompt(next_topic)\n",
    "    cg_id_to_refined_next_topic[cg_id] = llm_generate(pipeline=pipeline, prompt=refine_prompt, max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     \"Explainable AI, conversational AI, and decision intelligence for business, finance, healthcare, security, and public sector applications.\"\n",
      "2     \"The intersection of artificial intelligence and human consciousness, exploring AI's implications on human identity and reality.\"\n",
      "3     \"AI, machine learning, and algorithmic trading intersecting with econophysics, quantitative hedge funds, and societal implications of technology.\"\n",
      "4     'AI, machine learning, natural language processing, low-code development, vector databases, self-hosted backends, AI-assisted creativity, AI-powered productivity, AI-generated art, AI-driven innovation, AI research, AI development, AI applications, AI tools, AI services, AI platforms, AI ecosystems, AI communities, ChatGPT, Quarkus, Redis Search, OpenShift, Strapi CMS, WebHooks, vector similarity searches, custom prompts, AI-generated portraits'\n"
     ]
    }
   ],
   "source": [
    "for cg_id, next_topic in cg_id_to_refined_next_topic.items():\n",
    "    print(cg_id, next_topic.split(\"\\n\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed back into FeedGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_generator = FeedGenerator(content_generators=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     \"Explainable AI, conversational AI, and decision intelligence for business, finance, healthcare, security, and public sector applications.\"\n",
      "exa_topic_child_of_1 fetching content\n",
      "Failed request for https://www.nocode.ai/building-explainable-ai/\n",
      "2     \"The intersection of artificial intelligence and human consciousness, exploring AI's implications on human identity and reality.\"\n",
      "exa_topic_child_of_2 fetching content\n",
      "3     \"AI, machine learning, and algorithmic trading intersecting with econophysics, quantitative hedge funds, and societal implications of technology.\"\n",
      "exa_topic_child_of_3 fetching content\n",
      "Failed request for https://wiki.santafe.edu/index.php/Machine_Learning,_Complexity_and_Market_Behavior\n",
      "4     'AI, machine learning, natural language processing, low-code development, vector databases, self-hosted backends, AI-assisted creativity, AI-powered productivity, AI-generated art, AI-driven innovation, AI research, AI development, AI applications, AI tools, AI services, AI platforms, AI ecosystems, AI communities, ChatGPT, Quarkus, Redis Search, OpenShift, Strapi CMS, WebHooks, vector similarity searches, custom prompts, AI-generated portraits'\n",
      "exa_topic_child_of_4 fetching content\n"
     ]
    }
   ],
   "source": [
    "for cg_id, next_topic in cg_id_to_refined_next_topic.items():\n",
    "    next_topic_sentence = next_topic.split(\"\\n\")[1]\n",
    "    print(cg_id, next_topic_sentence)\n",
    "    feed_generator.add_content_generator(ExaTopicFeeder(name=f\"exa_topic_child_of_{cg_id}\", \n",
    "                                                        description=\"ExaTopicFeeder generated by summarizing the parent content that was clicked on\",\n",
    "                                                        topic=next_topic_sentence,\n",
    "                                                        parent_generator_id=cg_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exa_topic_overall_summary_from_o1 fetching content\n",
      "Content with URL 'https://haltia.ai/' already exists in the database and will not be added.\n",
      "Content with URL 'https://www.personal.ai/yours' already exists in the database and will not be added.\n",
      "Content with URL 'https://pi.ai/home' already exists in the database and will not be added.\n",
      "Content with URL 'https://snoop.personal.ai/' already exists in the database and will not be added.\n",
      "Content with URL 'https://www.personal.ai/your-true-personal-ai' already exists in the database and will not be added.\n"
     ]
    }
   ],
   "source": [
    "o1_resp = \"Personal AI assistants that are private and on-device, trained on personal data to become human-like extensions of oneself, enhancing memory and human connections, integrating AI into daily life with a focus on data privacy, explainable AI, and responsible AI.\"\n",
    "feed_generator.add_content_generator(ExaTopicFeeder(name=f\"exa_topic_overall_summary_from_o1\", \n",
    "                                                        description=\"ExaTopicFeeder generated by summarizing everything using ChatGPT o1\",\n",
    "                                                        topic=o1_resp, parent_generator_id=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hindsight_exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
